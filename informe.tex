\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{float}

\geometry{margin=2.5cm}

% Configuración de listings para C++
\lstset{
    language=C++,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{gray},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    frame=single,
    breaklines=true,
    captionpos=b
}

\title{\textbf{Algoritmos de Ordenamiento y Búsqueda Paralelos}}
\author{Programación Paralela}
\date{Noviembre 2025}

\begin{document}

\maketitle

\begin{abstract}
Este informe presenta la implementación y análisis de dos algoritmos paralelos: Shearsort para ordenamiento de matrices y P-BSA para búsqueda binaria. Se evalúa el rendimiento mediante métricas de speedup y walltime, comparando las versiones secuenciales con sus contrapartes paralelas implementadas usando OpenMP. Los resultados demuestran que la paralelización es efectiva para problemas de tamaño suficiente, aunque el overhead puede superar el beneficio en casos pequeños.
\end{abstract}

\section{Introducción}

Los algoritmos paralelos permiten aprovechar arquitecturas multi-núcleo para reducir el tiempo de ejecución. En este trabajo se implementan:

\begin{itemize}
    \item \textbf{Shearsort}: Algoritmo de ordenamiento paralelo para matrices $n \times n$ en orden snake-like
    \item \textbf{P-BSA}: Versión paralela del algoritmo de búsqueda binaria
\end{itemize}

El objetivo es medir el speedup real y compararlo con las predicciones teóricas del análisis asintótico.

\section{Algoritmo Shearsort}

\subsection{Descripción del Algoritmo}

Shearsort ordena una matriz $n \times n$ en orden snake-like mediante iteraciones alternadas de ordenamiento de filas y columnas. El algoritmo ejecuta $\lfloor \log_2(n) \rfloor + 1$ iteraciones, donde cada iteración consiste en:

\begin{enumerate}
    \item \textbf{Sort-row}: Ordenar filas pares ascendente e impares descendente
    \item \textbf{Sort-column}: Ordenar todas las columnas ascendente
\end{enumerate}

\subsection{Implementación}

Se implementaron tres versiones:

\begin{itemize}
    \item \textbf{Secuencial}: Procesa filas y columnas secuencialmente
    \item \textbf{Paralela}: Usa \texttt{\#pragma omp parallel for} para paralelizar
    \item \textbf{Alternativa}: Usa solo sort-row con transposición de matriz
\end{itemize}

\begin{lstlisting}[caption={Shearsort Paralelo - Fragmento Principal}]
void shearsort(int n, vector<vector<int>>& M) {
    int iterations = (int)log2(n) + 1;
    
    for (int iter = 0; iter < iterations; iter++) {
        // Ordenar filas en paralelo
        #pragma omp parallel for
        for (int tid = 0; tid < n; tid++) {
            sortRow(M, tid, tid % 2 == 0);
        }
        
        // Ordenar columnas en paralelo
        #pragma omp parallel for
        for (int tid = 0; tid < n; tid++) {
            sortColumn(M, tid);
        }
    }
}
\end{lstlisting}

\subsection{Resultados Experimentales}

La Tabla~\ref{tab:shearsort} muestra los tiempos de ejecución y speedup para diferentes tamaños de matriz.

\begin{table}[H]
\centering
\caption{Resultados de Shearsort con diferentes configuraciones}
\label{tab:shearsort}
\begin{tabular}{@{}cccccc@{}}
\toprule
\textbf{Tamaño} & \textbf{Secuencial} & \textbf{2 hilos} & \textbf{4 hilos} & \textbf{Speedup} & \textbf{Eficiencia} \\
                & \textbf{(ms)}       & \textbf{(ms)}    & \textbf{(ms)}    & \textbf{(4h)}    & \textbf{(4h)}       \\ \midrule
$8 \times 8$    & 0.008               & 0.020            & 0.330            & 0.02x            & 0.5\%               \\
$16 \times 16$  & 0.030               & 0.080            & 0.420            & 0.07x            & 1.8\%               \\
$32 \times 32$  & 0.240               & 0.180            & 0.240            & 1.00x            & 25.0\%              \\
$64 \times 64$  & 0.920               & 0.600            & 0.590            & 1.56x            & 39.0\%              \\
$128 \times 128$& 3.780               & 3.170            & 2.140            & \textbf{1.77x}   & \textbf{44.3\%}     \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Análisis Asintótico}

\textbf{Complejidad temporal:}
\begin{itemize}
    \item \textbf{Secuencial}: $O(n^2 \log^2 n)$
    \begin{itemize}
        \item Iteraciones: $\lfloor \log_2(n) \rfloor + 1$
        \item Por iteración: $n$ ordenamientos de tamaño $n \rightarrow O(n^2 \log n)$
    \end{itemize}
    \item \textbf{Paralelo} (con $P = n$ procesadores): $O(n \log^2 n)$
\end{itemize}

\textbf{Speedup teórico}: $S_{max} = \frac{n}{\log n}$ con $n$ procesadores

\textbf{Speedup observado}: Máximo 1.77x con 4 hilos (limitado por hardware real)

\subsection{Comparación de Implementaciones}

La Tabla~\ref{tab:shearsort-comp} compara la versión normal con la alternativa que usa transposición.

\begin{table}[H]
\centering
\caption{Comparación Shearsort vs Alternative-Shearsort}
\label{tab:shearsort-comp}
\begin{tabular}{@{}cccc@{}}
\toprule
\textbf{Tamaño} & \textbf{Normal (ms)} & \textbf{Alternativa (ms)} & \textbf{Diferencia (ms)} \\ \midrule
$16 \times 16$  & 0.13                 & 0.09                      & 0.04                     \\
$32 \times 32$  & 0.80                 & 0.31                      & 0.49                     \\
$64 \times 64$  & 0.36                 & 2.02                      & -1.66                    \\ \bottomrule
\end{tabular}
\end{table}

La versión alternativa es más rápida en matrices pequeñas pero pierde rendimiento en matrices grandes debido al overhead de las transposiciones.

\section{Algoritmo P-BSA}

\subsection{Descripción del Algoritmo}

P-BSA (Parallel Binary Search Algorithm) divide el arreglo ordenado en $P$ subsecuencias. Cada procesador verifica si el elemento buscado está en su rango y realiza búsqueda binaria local si es necesario.

\subsection{Implementación}

Se implementaron dos versiones:

\begin{itemize}
    \item \textbf{Secuencial}: Búsqueda binaria clásica $O(\log n)$
    \item \textbf{Paralela}: División del espacio entre $P$ procesadores
\end{itemize}

\begin{lstlisting}[caption={P-BSA Paralelo - Fragmento Principal}]
int parallelBinarySearch(const vector<int>& arr, 
                        int target, int numProcessors) {
    int n = arr.size();
    int result = -1;
    bool found = false;
    
    #pragma omp parallel num_threads(numProcessors) \
                shared(found, result)
    {
        int tid = omp_get_thread_num();
        int chunkSize = (n + numThreads - 1) / numThreads;
        int start = tid * chunkSize;
        int end = min(start + chunkSize - 1, n - 1);
        
        if (!found && start <= end) {
            if (arr[start] <= target && target <= arr[end]) {
                // Busqueda binaria local
                // ...
            }
        }
    }
    return result;
}
\end{lstlisting}

\subsection{Resultados Experimentales}

La Tabla~\ref{tab:pbsa} muestra los tiempos para búsquedas en arreglos ordenados (1000 búsquedas por tamaño).

\begin{table}[H]
\centering
\caption{Resultados de P-BSA con valores ordenados}
\label{tab:pbsa}
\begin{tabular}{@{}ccccc@{}}
\toprule
\textbf{Tamaño} & \textbf{Secuencial} & \textbf{4 hilos} & \textbf{Speedup} & \textbf{Encontrados} \\
                & \textbf{(ms)}       & \textbf{(ms)}    & \textbf{(4h)}    &                      \\ \midrule
100K            & 0.054               & 2.02             & 0.03x            & 500/1000             \\
500K            & 0.12                & 0.88             & 0.14x            & 500/1000             \\
1M              & 0.14                & 0.99             & 0.14x            & 500/1000             \\
5M              & 0.23                & 1.03             & 0.22x            & 500/1000             \\
10M             & 0.29                & 2.36             & 0.12x            & 500/1000             \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Análisis Asintótico}

\textbf{Complejidad temporal:}
\begin{itemize}
    \item \textbf{Secuencial}: $O(\log n)$
    \item \textbf{Paralelo}: $O(\frac{\log n}{P})$ (teórico)
\end{itemize}

\textbf{Speedup teórico}: Hasta $P$ procesadores (limitado por Ley de Amdahl)

\textbf{Speedup observado}: $< 1.0$ (versión paralela más lenta)

\textbf{Razón}: El overhead de paralelización ($O(P)$ para crear hilos y sincronizar) supera el beneficio cuando $\log n$ es pequeño. Para $n = 10^7$, se requieren solo $\log_2(10^7) \approx 23$ comparaciones, insuficientes para amortizar el costo de paralelización.

\subsection{Pruebas con Valores NO Ordenados}

Las pruebas con arreglos no ordenados confirmaron que la búsqueda binaria \textbf{no funciona correctamente} sin ordenamiento previo. Después de ordenar los datos, las búsquedas son exitosas, demostrando la importancia del requisito de datos ordenados para este algoritmo.

\section{Comparación Teoría vs Práctica}

\subsection{Shearsort}

\begin{itemize}
    \item \textbf{Teoría predice}: Speedup de $\frac{n}{\log n}$ con $n$ procesadores
    \item \textbf{Práctica observa}: Speedup máximo 1.77x con 4 hilos
    \item \textbf{Diferencias}:
    \begin{itemize}
        \item Sistema tiene solo 4 núcleos físicos (no $n$)
        \item Overhead de sincronización no modelado en teoría
        \item HyperThreading (8 hilos lógicos) no mejora rendimiento
    \end{itemize}
\end{itemize}

\subsection{P-BSA}

\begin{itemize}
    \item \textbf{Teoría predice}: Speedup hasta $P$ procesadores
    \item \textbf{Práctica observa}: Speedup $< 1.0$ (degradación)
    \item \textbf{Razones}:
    \begin{itemize}
        \item $\log n$ es demasiado pequeño para paralelizar efectivamente
        \item Overhead de creación de hilos domina el tiempo total
        \item Granularidad muy fina (microsegundos por búsqueda)
    \end{itemize}
\end{itemize}

\section{Metodología Experimental}

\subsection{Sistema de Prueba}

\begin{itemize}
    \item \textbf{CPU}: Intel Core i5-9300H @ 2.40GHz
    \item \textbf{Núcleos}: 4 físicos, 8 lógicos (HyperThreading)
    \item \textbf{Compilador}: g++ 6.3.0 con optimización -O3
    \item \textbf{Paralelización}: OpenMP
\end{itemize}

\subsection{Medición de Tiempos}

Se utilizó \texttt{std::chrono::high\_resolution\_clock} con precisión de microsegundos:

\begin{lstlisting}[caption={Medición de Walltime}]
auto start = high_resolution_clock::now();
shearsort(n, M);  // O binarysearch()
auto end = high_resolution_clock::now();
auto duration = duration_cast<microseconds>(end - start);
\end{lstlisting}

\subsection{Métricas Calculadas}

\begin{itemize}
    \item \textbf{Speedup}: $S = \frac{T_{secuencial}}{T_{paralelo}}$
    \item \textbf{Eficiencia}: $E = \frac{S}{P}$ donde $P$ es el número de procesadores
\end{itemize}

\section{Conclusiones}

\subsection{Shearsort}

\begin{enumerate}
    \item La paralelización es \textbf{efectiva para matrices grandes} ($n \geq 64$)
    \item El speedup máximo observado fue \textbf{1.77x con 4 hilos} en matriz $128 \times 128$
    \item Para matrices pequeñas ($n < 32$), el overhead supera el beneficio
    \item La configuración óptima es \textbf{4 hilos} (igual al número de núcleos físicos)
    \item Usar 8 hilos degrada el rendimiento por sobresuscripción
\end{enumerate}

\subsection{P-BSA}

\begin{enumerate}
    \item La paralelización de búsqueda binaria individual \textbf{no es efectiva}
    \item El speedup observado es $< 1.0$ debido al overhead
    \item La naturaleza logarítmica ($O(\log n)$) proporciona poco trabajo para paralelizar
    \item \textbf{Mejor estrategia}: Paralelizar múltiples búsquedas independientes
    \item Los datos \textbf{deben estar ordenados} para que el algoritmo funcione
\end{enumerate}

\subsection{Lecciones Generales}

\begin{enumerate}
    \item \textbf{No todo debe paralelizarse}: Evaluar relación trabajo/overhead
    \item \textbf{Tamaño del problema importa}: Paralelización beneficia problemas grandes
    \item \textbf{Teoría vs práctica}: Hardware real limita speedup teórico
    \item \textbf{Número óptimo de hilos}: Igual al número de núcleos físicos
    \item \textbf{Medición precisa es esencial}: Usar herramientas como chrono
\end{enumerate}

\section{Referencias}

\begin{enumerate}
    \item Akl, S. G. (1997). \textit{Parallel Computation: Models and Methods}. Prentice Hall.
    \item Quinn, M. J. (2004). \textit{Parallel Programming in C with MPI and OpenMP}. McGraw-Hill.
    \item OpenMP Architecture Review Board. \textit{OpenMP Application Program Interface Version 4.5}.
\end{enumerate}

\end{document}
